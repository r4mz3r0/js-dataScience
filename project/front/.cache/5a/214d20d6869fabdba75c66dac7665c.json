{"id":"node_modules/vega-lite/build/src/compile/data/parse.js","dependencies":[{"name":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js.map","includedInParent":true,"mtime":499162500000},{"name":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/package.json","includedInParent":true,"mtime":1593715260815},{"name":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/package.json","includedInParent":true,"mtime":499162500000},{"name":"tslib","loc":{"line":3,"column":22},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/tslib/tslib.es6.js"},{"name":"../../data","loc":{"line":4,"column":21},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/data.js"},{"name":"../../log","loc":{"line":5,"column":39},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/log.js"},{"name":"../../transform","loc":{"line":6,"column":26},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/transform.js"},{"name":"../../util","loc":{"line":7,"column":21},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/util.js"},{"name":"../model","loc":{"line":8,"column":22},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/model.js"},{"name":"../selection/selection","loc":{"line":9,"column":26},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/selection/selection.js"},{"name":"./aggregate","loc":{"line":10,"column":26},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/aggregate.js"},{"name":"./bin","loc":{"line":11,"column":20},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/bin.js"},{"name":"./calculate","loc":{"line":12,"column":26},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/calculate.js"},{"name":"./dataflow","loc":{"line":13,"column":25},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/dataflow.js"},{"name":"./facet","loc":{"line":14,"column":22},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/facet.js"},{"name":"./filter","loc":{"line":15,"column":23},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/filter.js"},{"name":"./filterinvalid","loc":{"line":16,"column":30},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/filterinvalid.js"},{"name":"./formatparse","loc":{"line":17,"column":28},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/formatparse.js"},{"name":"./geojson","loc":{"line":18,"column":24},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/geojson.js"},{"name":"./geopoint","loc":{"line":19,"column":25},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/geopoint.js"},{"name":"./identifier","loc":{"line":20,"column":27},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/identifier.js"},{"name":"./index","loc":{"line":21,"column":22},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/index.js"},{"name":"./lookup","loc":{"line":22,"column":23},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/lookup.js"},{"name":"./source","loc":{"line":23,"column":23},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/source.js"},{"name":"./stack","loc":{"line":24,"column":22},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/stack.js"},{"name":"./timeunit","loc":{"line":25,"column":25},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/timeunit.js"},{"name":"./window","loc":{"line":26,"column":23},"parent":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/parse.js","resolved":"/home/ramsiro/Desktop/JavaScriptDataScience/js-dataScience/project/front/node_modules/vega-lite/build/src/compile/data/window.js"}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tslib_1 = require(\"tslib\");\nvar data_1 = require(\"../../data\");\nvar log = tslib_1.__importStar(require(\"../../log\"));\nvar transform_1 = require(\"../../transform\");\nvar util_1 = require(\"../../util\");\nvar model_1 = require(\"../model\");\nvar selection_1 = require(\"../selection/selection\");\nvar aggregate_1 = require(\"./aggregate\");\nvar bin_1 = require(\"./bin\");\nvar calculate_1 = require(\"./calculate\");\nvar dataflow_1 = require(\"./dataflow\");\nvar facet_1 = require(\"./facet\");\nvar filter_1 = require(\"./filter\");\nvar filterinvalid_1 = require(\"./filterinvalid\");\nvar formatparse_1 = require(\"./formatparse\");\nvar geojson_1 = require(\"./geojson\");\nvar geopoint_1 = require(\"./geopoint\");\nvar identifier_1 = require(\"./identifier\");\nvar index_1 = require(\"./index\");\nvar lookup_1 = require(\"./lookup\");\nvar source_1 = require(\"./source\");\nvar stack_1 = require(\"./stack\");\nvar timeunit_1 = require(\"./timeunit\");\nvar window_1 = require(\"./window\");\nfunction parseRoot(model, sources) {\n    if (model.data || !model.parent) {\n        // if the model defines a data source or is the root, create a source node\n        var source = new source_1.SourceNode(model.data);\n        var hash = source.hash();\n        if (hash in sources) {\n            // use a reference if we already have a source\n            return sources[hash];\n        }\n        else {\n            // otherwise add a new one\n            sources[hash] = source;\n            return source;\n        }\n    }\n    else {\n        // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n        return model.parent.component.data.facetRoot ? model.parent.component.data.facetRoot : model.parent.component.data.main;\n    }\n}\n/**\n * Parses a transforms array into a chain of connected dataflow nodes.\n */\nfunction parseTransformArray(head, model, ancestorParse) {\n    var lookupCounter = 0;\n    model.transforms.forEach(function (t) {\n        if (transform_1.isCalculate(t)) {\n            head = new calculate_1.CalculateNode(head, t);\n            ancestorParse.set(t.as, 'derived', false);\n        }\n        else if (transform_1.isFilter(t)) {\n            head = formatparse_1.ParseNode.makeImplicitFromFilterTransform(head, t, ancestorParse) || head;\n            head = new filter_1.FilterNode(head, model, t.filter);\n        }\n        else if (transform_1.isBin(t)) {\n            var bin = head = bin_1.BinNode.makeFromTransform(head, t, model);\n            for (var _i = 0, _a = util_1.keys(bin.producedFields()); _i < _a.length; _i++) {\n                var field = _a[_i];\n                ancestorParse.set(field, 'number', false);\n            }\n        }\n        else if (transform_1.isTimeUnit(t)) {\n            head = timeunit_1.TimeUnitNode.makeFromTransform(head, t);\n            ancestorParse.set(t.as, 'date', false);\n        }\n        else if (transform_1.isAggregate(t)) {\n            var agg = head = aggregate_1.AggregateNode.makeFromTransform(head, t);\n            if (selection_1.requiresSelectionId(model)) {\n                head = new identifier_1.IdentifierNode(head);\n            }\n            for (var _b = 0, _c = util_1.keys(agg.producedFields()); _b < _c.length; _b++) {\n                var field = _c[_b];\n                ancestorParse.set(field, 'derived', false);\n            }\n        }\n        else if (transform_1.isLookup(t)) {\n            var lookup = head = lookup_1.LookupNode.make(head, model, t, lookupCounter++);\n            for (var _d = 0, _e = util_1.keys(lookup.producedFields()); _d < _e.length; _d++) {\n                var field = _e[_d];\n                ancestorParse.set(field, 'derived', false);\n            }\n        }\n        else if (transform_1.isWindow(t)) {\n            var window_2 = head = new window_1.WindowTransformNode(head, t);\n            for (var _f = 0, _g = util_1.keys(window_2.producedFields()); _f < _g.length; _f++) {\n                var field = _g[_f];\n                ancestorParse.set(field, 'derived', false);\n            }\n        }\n        else if (transform_1.isStack(t)) {\n            var stack = head = stack_1.StackNode.makeFromTransform(head, t);\n            for (var _h = 0, _j = util_1.keys(stack.producedFields()); _h < _j.length; _h++) {\n                var field = _j[_h];\n                ancestorParse.set(field, 'derived', false);\n            }\n        }\n        else {\n            log.warn(log.message.invalidTransformIgnored(t));\n            return;\n        }\n    });\n    return head;\n}\nexports.parseTransformArray = parseTransformArray;\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n  Invalid Filter\n         |\n         v\n   +----------+\n   |   Main   |\n   +----------+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\nfunction parseData(model) {\n    var head = parseRoot(model, model.component.data.sources);\n    var _a = model.component.data, outputNodes = _a.outputNodes, outputNodeRefCounts = _a.outputNodeRefCounts;\n    var ancestorParse = model.parent ? model.parent.component.data.ancestorParse.clone() : new index_1.AncestorParse();\n    // format.parse: null means disable parsing\n    if (model.data && model.data.format && model.data.format.parse === null) {\n        ancestorParse.parseNothing = true;\n    }\n    head = formatparse_1.ParseNode.makeExplicit(head, model, ancestorParse) || head;\n    // Default discrete selections require an identifier transform to\n    // uniquely identify data points as the _id field is volatile. Add\n    // this transform at the head of our pipeline such that the identifier\n    // field is available for all subsequent datasets. Additional identifier\n    // transforms will be necessary when new tuples are constructed\n    // (e.g., post-aggregation).\n    if (selection_1.requiresSelectionId(model) && (model_1.isUnitModel(model) || model_1.isLayerModel(model))) {\n        head = new identifier_1.IdentifierNode(head);\n    }\n    // HACK: This is equivalent for merging bin extent for union scale.\n    // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n    var parentIsLayer = model.parent && model_1.isLayerModel(model.parent);\n    if (model_1.isUnitModel(model) || model_1.isFacetModel(model)) {\n        if (parentIsLayer) {\n            head = bin_1.BinNode.makeFromEncoding(head, model) || head;\n        }\n    }\n    if (model.transforms.length > 0) {\n        head = parseTransformArray(head, model, ancestorParse);\n    }\n    head = formatparse_1.ParseNode.makeImplicitFromEncoding(head, model, ancestorParse) || head;\n    if (model_1.isUnitModel(model)) {\n        head = geojson_1.GeoJSONNode.parseAll(head, model);\n        head = geopoint_1.GeoPointNode.parseAll(head, model);\n    }\n    if (model_1.isUnitModel(model) || model_1.isFacetModel(model)) {\n        if (!parentIsLayer) {\n            head = bin_1.BinNode.makeFromEncoding(head, model) || head;\n        }\n        head = timeunit_1.TimeUnitNode.makeFromEncoding(head, model) || head;\n        head = calculate_1.CalculateNode.parseAllForSortIndex(head, model);\n    }\n    // add an output node pre aggregation\n    var rawName = model.getName(data_1.RAW);\n    var raw = new dataflow_1.OutputNode(head, rawName, data_1.RAW, outputNodeRefCounts);\n    outputNodes[rawName] = raw;\n    head = raw;\n    if (model_1.isUnitModel(model)) {\n        var agg = aggregate_1.AggregateNode.makeFromEncoding(head, model);\n        if (agg) {\n            head = agg;\n            if (selection_1.requiresSelectionId(model)) {\n                head = new identifier_1.IdentifierNode(head);\n            }\n        }\n        head = stack_1.StackNode.makeFromEncoding(head, model) || head;\n    }\n    if (model_1.isUnitModel(model)) {\n        head = filterinvalid_1.FilterInvalidNode.make(head, model) || head;\n    }\n    // output node for marks\n    var mainName = model.getName(data_1.MAIN);\n    var main = new dataflow_1.OutputNode(head, mainName, data_1.MAIN, outputNodeRefCounts);\n    outputNodes[mainName] = main;\n    head = main;\n    // add facet marker\n    var facetRoot = null;\n    if (model_1.isFacetModel(model)) {\n        var facetName = model.getName('facet');\n        // Derive new sort index field for facet's sort array\n        head = calculate_1.CalculateNode.parseAllForSortIndex(head, model);\n        // Derive new aggregate (via window) for facet's sort field\n        // TODO: use JoinAggregate once we have it\n        // augment data source with new fields for crossed facet\n        head = window_1.WindowTransformNode.makeFromFacet(head, model.facet) || head;\n        facetRoot = new facet_1.FacetNode(head, model, facetName, main.getSource());\n        outputNodes[facetName] = facetRoot;\n        head = facetRoot;\n    }\n    return tslib_1.__assign({}, model.component.data, { outputNodes: outputNodes,\n        outputNodeRefCounts: outputNodeRefCounts,\n        raw: raw,\n        main: main,\n        facetRoot: facetRoot,\n        ancestorParse: ancestorParse });\n}\nexports.parseData = parseData;\n"},"sourceMaps":{"js":{"version":3,"file":"parse.js","sourceRoot":"","sources":["../../../../src/compile/data/parse.ts"],"names":[],"mappings":";;;AAAA,mCAAqC;AACrC,qDAAiC;AACjC,6CAAmH;AACnH,mCAAsC;AACtC,kCAAwE;AACxE,oDAA2D;AAC3D,yCAA0C;AAC1C,6BAA8B;AAC9B,yCAA0C;AAC1C,uCAAoD;AACpD,iCAAkC;AAClC,mCAAoC;AACpC,iDAAkD;AAClD,6CAAwC;AACxC,qCAAsC;AACtC,uCAAwC;AACxC,2CAA4C;AAC5C,iCAAqD;AACrD,mCAAoC;AACpC,mCAAoC;AACpC,iCAAkC;AAClC,uCAAwC;AACxC,mCAA6C;AAE7C,mBAAmB,KAAY,EAAE,OAAyB;IACxD,IAAI,KAAK,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE;QAC/B,0EAA0E;QAC1E,IAAM,MAAM,GAAG,IAAI,mBAAU,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;QAC1C,IAAM,IAAI,GAAG,MAAM,CAAC,IAAI,EAAE,CAAC;QAC3B,IAAI,IAAI,IAAI,OAAO,EAAE;YACnB,8CAA8C;YAC9C,OAAO,OAAO,CAAC,IAAI,CAAC,CAAC;SACtB;aAAM;YACL,0BAA0B;YAC1B,OAAO,CAAC,IAAI,CAAC,GAAG,MAAM,CAAC;YACvB,OAAO,MAAM,CAAC;SACf;KACF;SAAM;QACL,qGAAqG;QACrG,OAAO,KAAK,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC;KACzH;AACH,CAAC;AAGD;;GAEG;AACH,6BAAoC,IAAkB,EAAE,KAAY,EAAE,aAA4B;IAChG,IAAI,aAAa,GAAG,CAAC,CAAC;IAEtB,KAAK,CAAC,UAAU,CAAC,OAAO,CAAC,UAAA,CAAC;QACxB,IAAI,uBAAW,CAAC,CAAC,CAAC,EAAE;YAClB,IAAI,GAAG,IAAI,yBAAa,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAClC,aAAa,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;SAC3C;aAAM,IAAI,oBAAQ,CAAC,CAAC,CAAC,EAAE;YACtB,IAAI,GAAG,uBAAS,CAAC,+BAA+B,CAAC,IAAI,EAAE,CAAC,EAAE,aAAa,CAAC,IAAI,IAAI,CAAC;YAEjF,IAAI,GAAG,IAAI,mBAAU,CAAC,IAAI,EAAE,KAAK,EAAE,CAAC,CAAC,MAAM,CAAC,CAAC;SAC9C;aAAM,IAAI,iBAAK,CAAC,CAAC,CAAC,EAAE;YACnB,IAAM,GAAG,GAAG,IAAI,GAAG,aAAO,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;YAE7D,KAAoB,UAA0B,EAA1B,KAAA,WAAI,CAAC,GAAG,CAAC,cAAc,EAAE,CAAC,EAA1B,cAA0B,EAA1B,IAA0B,EAAE;gBAA3C,IAAM,KAAK,SAAA;gBACd,aAAa,CAAC,GAAG,CAAC,KAAK,EAAE,QAAQ,EAAE,KAAK,CAAC,CAAC;aAC3C;SAEF;aAAM,IAAI,sBAAU,CAAC,CAAC,CAAC,EAAE;YACxB,IAAI,GAAG,uBAAY,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAE/C,aAAa,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;SACxC;aAAM,IAAI,uBAAW,CAAC,CAAC,CAAC,EAAE;YACzB,IAAM,GAAG,GAAG,IAAI,GAAG,yBAAa,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAE5D,IAAI,+BAAmB,CAAC,KAAK,CAAC,EAAE;gBAC9B,IAAI,GAAG,IAAI,2BAAc,CAAC,IAAI,CAAC,CAAC;aACjC;YAED,KAAoB,UAA0B,EAA1B,KAAA,WAAI,CAAC,GAAG,CAAC,cAAc,EAAE,CAAC,EAA1B,cAA0B,EAA1B,IAA0B,EAAE;gBAA3C,IAAM,KAAK,SAAA;gBACd,aAAa,CAAC,GAAG,CAAC,KAAK,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;aAC5C;SACF;aAAM,IAAI,oBAAQ,CAAC,CAAC,CAAC,EAAE;YACtB,IAAM,MAAM,GAAG,IAAI,GAAG,mBAAU,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,CAAC,EAAE,aAAa,EAAE,CAAC,CAAC;YAEvE,KAAoB,UAA6B,EAA7B,KAAA,WAAI,CAAC,MAAM,CAAC,cAAc,EAAE,CAAC,EAA7B,cAA6B,EAA7B,IAA6B,EAAE;gBAA9C,IAAM,KAAK,SAAA;gBACd,aAAa,CAAC,GAAG,CAAC,KAAK,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;aAC5C;SACF;aAAM,IAAI,oBAAQ,CAAC,CAAC,CAAC,EAAE;YACtB,IAAM,QAAM,GAAG,IAAI,GAAG,IAAI,4BAAmB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAEvD,KAAoB,UAA6B,EAA7B,KAAA,WAAI,CAAC,QAAM,CAAC,cAAc,EAAE,CAAC,EAA7B,cAA6B,EAA7B,IAA6B,EAAE;gBAA9C,IAAM,KAAK,SAAA;gBACd,aAAa,CAAC,GAAG,CAAC,KAAK,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;aAC5C;SACF;aAAM,IAAI,mBAAO,CAAC,CAAC,CAAC,EAAE;YACrB,IAAM,KAAK,GAAG,IAAI,GAAG,iBAAS,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAE1D,KAAoB,UAA4B,EAA5B,KAAA,WAAI,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,EAA5B,cAA4B,EAA5B,IAA4B,EAAE;gBAA7C,IAAM,KAAK,SAAA;gBACd,aAAa,CAAC,GAAG,CAAC,KAAK,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;aAC5C;SACF;aAAM;YACL,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,uBAAuB,CAAC,CAAC,CAAC,CAAC,CAAC;YACjD,OAAO;SACR;IACH,CAAC,CAAC,CAAC;IAEH,OAAO,IAAI,CAAC;AACd,CAAC;AAzDD,kDAyDC;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqDE;AAEF,mBAA0B,KAAY;IACpC,IAAI,IAAI,GAAG,SAAS,CAAC,KAAK,EAAE,KAAK,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IAEpD,IAAA,yBAAyD,EAAxD,4BAAW,EAAE,4CAAmB,CAAyB;IAChE,IAAM,aAAa,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,aAAa,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC,IAAI,qBAAa,EAAE,CAAC;IAE7G,2CAA2C;IAC3C,IAAI,KAAK,CAAC,IAAI,IAAI,KAAK,CAAC,IAAI,CAAC,MAAM,IAAI,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,KAAK,IAAI,EAAE;QACvE,aAAa,CAAC,YAAY,GAAG,IAAI,CAAC;KACnC;IAED,IAAI,GAAG,uBAAS,CAAC,YAAY,CAAC,IAAI,EAAE,KAAK,EAAE,aAAa,CAAC,IAAI,IAAI,CAAC;IAElE,iEAAiE;IACjE,kEAAkE;IAClE,sEAAsE;IACtE,wEAAwE;IACxE,+DAA+D;IAC/D,4BAA4B;IAC5B,IAAI,+BAAmB,CAAC,KAAK,CAAC,IAAI,CAAC,mBAAW,CAAC,KAAK,CAAC,IAAI,oBAAY,CAAC,KAAK,CAAC,CAAC,EAAE;QAC7E,IAAI,GAAG,IAAI,2BAAc,CAAC,IAAI,CAAC,CAAC;KACjC;IAED,mEAAmE;IACnE,+GAA+G;IAC/G,IAAM,aAAa,GAAG,KAAK,CAAC,MAAM,IAAI,oBAAY,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;IACjE,IAAI,mBAAW,CAAC,KAAK,CAAC,IAAI,oBAAY,CAAC,KAAK,CAAC,EAAE;QAC7C,IAAI,aAAa,EAAE;YACjB,IAAI,GAAG,aAAO,CAAC,gBAAgB,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,IAAI,CAAC;SACtD;KACF;IAED,IAAI,KAAK,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;QAC/B,IAAI,GAAG,mBAAmB,CAAC,IAAI,EAAE,KAAK,EAAE,aAAa,CAAC,CAAC;KACxD;IAED,IAAI,GAAG,uBAAS,CAAC,wBAAwB,CAAC,IAAI,EAAE,KAAK,EAAE,aAAa,CAAC,IAAI,IAAI,CAAC;IAE9E,IAAI,mBAAW,CAAC,KAAK,CAAC,EAAE;QACtB,IAAI,GAAG,qBAAW,CAAC,QAAQ,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QACzC,IAAI,GAAG,uBAAY,CAAC,QAAQ,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;KAC3C;IAED,IAAI,mBAAW,CAAC,KAAK,CAAC,IAAI,oBAAY,CAAC,KAAK,CAAC,EAAE;QAE7C,IAAI,CAAC,aAAa,EAAE;YAClB,IAAI,GAAG,aAAO,CAAC,gBAAgB,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,IAAI,CAAC;SACtD;QAED,IAAI,GAAG,uBAAY,CAAC,gBAAgB,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,IAAI,CAAC;QAC1D,IAAI,GAAG,yBAAa,CAAC,oBAAoB,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;KACxD;IAED,qCAAqC;IACrC,IAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,UAAG,CAAC,CAAC;IACnC,IAAM,GAAG,GAAG,IAAI,qBAAU,CAAC,IAAI,EAAE,OAAO,EAAE,UAAG,EAAE,mBAAmB,CAAC,CAAC;IACpE,WAAW,CAAC,OAAO,CAAC,GAAG,GAAG,CAAC;IAC3B,IAAI,GAAG,GAAG,CAAC;IAEX,IAAI,mBAAW,CAAC,KAAK,CAAC,EAAE;QACtB,IAAM,GAAG,GAAG,yBAAa,CAAC,gBAAgB,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QACxD,IAAI,GAAG,EAAE;YACP,IAAI,GAAG,GAAG,CAAC;YAEX,IAAI,+BAAmB,CAAC,KAAK,CAAC,EAAE;gBAC9B,IAAI,GAAG,IAAI,2BAAc,CAAC,IAAI,CAAC,CAAC;aACjC;SACF;QAED,IAAI,GAAG,iBAAS,CAAC,gBAAgB,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,IAAI,CAAC;KACxD;IAED,IAAI,mBAAW,CAAC,KAAK,CAAC,EAAE;QACtB,IAAI,GAAG,iCAAiB,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,IAAI,IAAI,CAAC;KACpD;IAED,wBAAwB;IACxB,IAAM,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC,WAAI,CAAC,CAAC;IACrC,IAAM,IAAI,GAAG,IAAI,qBAAU,CAAC,IAAI,EAAE,QAAQ,EAAE,WAAI,EAAE,mBAAmB,CAAC,CAAC;IACvE,WAAW,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC;IAC7B,IAAI,GAAG,IAAI,CAAC;IAEZ,mBAAmB;IACnB,IAAI,SAAS,GAAG,IAAI,CAAC;IACrB,IAAI,oBAAY,CAAC,KAAK,CAAC,EAAE;QACvB,IAAM,SAAS,GAAG,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QAEzC,qDAAqD;QACrD,IAAI,GAAG,yBAAa,CAAC,oBAAoB,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QAEvD,2DAA2D;QAC3D,0CAA0C;QAC1C,wDAAwD;QACxD,IAAI,GAAG,4BAAmB,CAAC,aAAa,CAAC,IAAI,EAAE,KAAK,CAAC,KAAK,CAAC,IAAI,IAAI,CAAC;QAEpE,SAAS,GAAG,IAAI,iBAAS,CAAC,IAAI,EAAE,KAAK,EAAE,SAAS,EAAE,IAAI,CAAC,SAAS,EAAE,CAAC,CAAC;QACpE,WAAW,CAAC,SAAS,CAAC,GAAG,SAAS,CAAC;QACnC,IAAI,GAAG,SAAS,CAAC;KAClB;IAED,4BACK,KAAK,CAAC,SAAS,CAAC,IAAI,IACvB,WAAW,aAAA;QACX,mBAAmB,qBAAA;QACnB,GAAG,KAAA;QACH,IAAI,MAAA;QACJ,SAAS,WAAA;QACT,aAAa,eAAA,IACb;AACJ,CAAC;AA7GD,8BA6GC","sourcesContent":["import {MAIN, RAW} from '../../data';\nimport * as log from '../../log';\nimport {isAggregate, isBin, isCalculate, isFilter, isLookup, isStack, isTimeUnit, isWindow} from '../../transform';\nimport {Dict, keys} from '../../util';\nimport {isFacetModel, isLayerModel, isUnitModel, Model} from '../model';\nimport {requiresSelectionId} from '../selection/selection';\nimport {AggregateNode} from './aggregate';\nimport {BinNode} from './bin';\nimport {CalculateNode} from './calculate';\nimport {DataFlowNode, OutputNode} from './dataflow';\nimport {FacetNode} from './facet';\nimport {FilterNode} from './filter';\nimport {FilterInvalidNode} from './filterinvalid';\nimport {ParseNode} from './formatparse';\nimport {GeoJSONNode} from './geojson';\nimport {GeoPointNode} from './geopoint';\nimport {IdentifierNode} from './identifier';\nimport {AncestorParse, DataComponent} from './index';\nimport {LookupNode} from './lookup';\nimport {SourceNode} from './source';\nimport {StackNode} from './stack';\nimport {TimeUnitNode} from './timeunit';\nimport {WindowTransformNode} from './window';\n\nfunction parseRoot(model: Model, sources: Dict<SourceNode>): DataFlowNode {\n  if (model.data || !model.parent) {\n    // if the model defines a data source or is the root, create a source node\n    const source = new SourceNode(model.data);\n    const hash = source.hash();\n    if (hash in sources) {\n      // use a reference if we already have a source\n      return sources[hash];\n    } else {\n      // otherwise add a new one\n      sources[hash] = source;\n      return source;\n    }\n  } else {\n    // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n    return model.parent.component.data.facetRoot ? model.parent.component.data.facetRoot : model.parent.component.data.main;\n  }\n}\n\n\n/**\n * Parses a transforms array into a chain of connected dataflow nodes.\n */\nexport function parseTransformArray(head: DataFlowNode, model: Model, ancestorParse: AncestorParse): DataFlowNode {\n  let lookupCounter = 0;\n\n  model.transforms.forEach(t => {\n    if (isCalculate(t)) {\n      head = new CalculateNode(head, t);\n      ancestorParse.set(t.as, 'derived', false);\n    } else if (isFilter(t)) {\n      head = ParseNode.makeImplicitFromFilterTransform(head, t, ancestorParse) || head;\n\n      head = new FilterNode(head, model, t.filter);\n    } else if (isBin(t)) {\n      const bin = head = BinNode.makeFromTransform(head, t, model);\n\n      for (const field of keys(bin.producedFields())) {\n        ancestorParse.set(field, 'number', false);\n      }\n\n    } else if (isTimeUnit(t)) {\n      head = TimeUnitNode.makeFromTransform(head, t);\n\n      ancestorParse.set(t.as, 'date', false);\n    } else if (isAggregate(t)) {\n      const agg = head = AggregateNode.makeFromTransform(head, t);\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n\n      for (const field of keys(agg.producedFields())) {\n        ancestorParse.set(field, 'derived', false);\n      }\n    } else if (isLookup(t)) {\n      const lookup = head = LookupNode.make(head, model, t, lookupCounter++);\n\n      for (const field of keys(lookup.producedFields())) {\n        ancestorParse.set(field, 'derived', false);\n      }\n    } else if (isWindow(t)) {\n      const window = head = new WindowTransformNode(head, t);\n\n      for (const field of keys(window.producedFields())) {\n        ancestorParse.set(field, 'derived', false);\n      }\n    } else if (isStack(t)) {\n      const stack = head = StackNode.makeFromTransform(head, t);\n\n      for (const field of keys(stack.producedFields())) {\n        ancestorParse.set(field, 'derived', false);\n      }\n    } else {\n      log.warn(log.message.invalidTransformIgnored(t));\n      return;\n    }\n  });\n\n  return head;\n}\n\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n  Invalid Filter\n         |\n         v\n   +----------+\n   |   Main   |\n   +----------+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\n\nexport function parseData(model: Model): DataComponent {\n  let head = parseRoot(model, model.component.data.sources);\n\n  const {outputNodes, outputNodeRefCounts} = model.component.data;\n  const ancestorParse = model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n\n  // format.parse: null means disable parsing\n  if (model.data && model.data.format && model.data.format.parse === null) {\n    ancestorParse.parseNothing = true;\n  }\n\n  head = ParseNode.makeExplicit(head, model, ancestorParse) || head;\n\n  // Default discrete selections require an identifier transform to\n  // uniquely identify data points as the _id field is volatile. Add\n  // this transform at the head of our pipeline such that the identifier\n  // field is available for all subsequent datasets. Additional identifier\n  // transforms will be necessary when new tuples are constructed\n  // (e.g., post-aggregation).\n  if (requiresSelectionId(model) && (isUnitModel(model) || isLayerModel(model))) {\n    head = new IdentifierNode(head);\n  }\n\n  // HACK: This is equivalent for merging bin extent for union scale.\n  // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n  const parentIsLayer = model.parent && isLayerModel(model.parent);\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) || head;\n    }\n  }\n\n  if (model.transforms.length > 0) {\n    head = parseTransformArray(head, model, ancestorParse);\n  }\n\n  head = ParseNode.makeImplicitFromEncoding(head, model, ancestorParse) || head;\n\n  if (isUnitModel(model)) {\n    head = GeoJSONNode.parseAll(head, model);\n    head = GeoPointNode.parseAll(head, model);\n  }\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n\n    if (!parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) || head;\n    }\n\n    head = TimeUnitNode.makeFromEncoding(head, model) || head;\n    head = CalculateNode.parseAllForSortIndex(head, model);\n  }\n\n  // add an output node pre aggregation\n  const rawName = model.getName(RAW);\n  const raw = new OutputNode(head, rawName, RAW, outputNodeRefCounts);\n  outputNodes[rawName] = raw;\n  head = raw;\n\n  if (isUnitModel(model)) {\n    const agg = AggregateNode.makeFromEncoding(head, model);\n    if (agg) {\n      head = agg;\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    }\n\n    head = StackNode.makeFromEncoding(head, model) || head;\n  }\n\n  if (isUnitModel(model)) {\n    head = FilterInvalidNode.make(head, model) || head;\n  }\n\n  // output node for marks\n  const mainName = model.getName(MAIN);\n  const main = new OutputNode(head, mainName, MAIN, outputNodeRefCounts);\n  outputNodes[mainName] = main;\n  head = main;\n\n  // add facet marker\n  let facetRoot = null;\n  if (isFacetModel(model)) {\n    const facetName = model.getName('facet');\n\n    // Derive new sort index field for facet's sort array\n    head = CalculateNode.parseAllForSortIndex(head, model);\n\n    // Derive new aggregate (via window) for facet's sort field\n    // TODO: use JoinAggregate once we have it\n    // augment data source with new fields for crossed facet\n    head = WindowTransformNode.makeFromFacet(head, model.facet) || head;\n\n    facetRoot = new FacetNode(head, model, facetName, main.getSource());\n    outputNodes[facetName] = facetRoot;\n    head = facetRoot;\n  }\n\n  return {\n    ...model.component.data,\n    outputNodes,\n    outputNodeRefCounts,\n    raw,\n    main,\n    facetRoot,\n    ancestorParse\n  };\n}\n"]}},"error":null,"hash":"2db1868190b68f06111a69901451d5ee","cacheData":{"env":{}}}